# МОИ ПРОЕКТЫ

---
## [Анализ A/B-теста, SQL, автообновление данных A/B-теста Projecc_2.ipynb](https://github.com/RomanFeofanov/my_projects/blob/main/Project_2.ipynb/"Ссылка на проект")
## Задача 1. A/B–тестирование
### Цель проекта:  
- проанализировать результаты A/B-теста новой механики оплаты;
- выбрать метрики;
- объяснить имеющиеся различия в значениях метрик разных групп;
- для групп разного размера определить являются ли различия статистически значимыми;
- сделать выводы о целесообразности запуска новой механики на всех пользователей.

### В мои задачи входило: 
- объединение 4-х файлов csv;
- выбор "рабочей" аудитории в группах из общей массы пользователей;
- выбор метрик;
- реализация функции проверки гипотез методом bootstrap.

### Результат:  
- в период проведения экспериментов были выявлены пользователи, которые совершили покупку, но не заходили на платформу в дни проведения эксперимента. Было сделано предположение, что произошла ошибка при записи данных;
- расчитаны CR в покупку (эффект отрицательный), ARPU и ARPPU (эффект положительный);
- было определено количество выбросов двух групп. Так как число выбросов небольшое, то было принято решение не убирать их из данных; 
- исходя из того, что данные распределены не нормально и дисперсии двух групп отличаются, то для оценки метрик в группах размер которых отличался в 4 раза принято решение использовать метод bootstrap;
- для того, чтобы понять взаимосвязаны ли два номинальных (дискретных) признака (группа - А/Б и факт покупки - купил/не купил), был применен критерий Хи-квадрат;
- различия в ARPU и ARPPU приняты статистически значимыми, различия в CR - статистически не значимыми;
- сделан вывод: новая механика оплаты даёт статистически значимый прирост в метриках ARPU и ARPPU, отрицательное изменение метрики CR не подтвердилось.

### В работе использовались:   
- библиотеки requests и urllib.parse для получения прямой ссылки и загрузки файлов с Яндекс.Диска;
- библиотеки tqdm.auto для визуализации прогресса;
- библиотеки pandas, seaborn, scipy.stats, matplotlib.pyplot, pingouin, statsmodels для обработки и визуализации данных.

## Задача 2. SQL
### Цель проекта:  
- написать оптимальный запрос, который даст информацию о количестве очень усердных студентов за октябрь 2021 года;
- в одном запросе выгрузить: ARPU, ARPAU, CR в покупку, СR активного пользователя в покупку, CR пользователя из активности по математике в покупку курса по математике;

### В мои задачи входило: 
- объединение таблиц различными видами джойнов;
- расчёт метрик.

### Результат:  
- запросы написаны и проверены в СУБД Clickhouse;

### В работе использовались:  
- подзапросы;
- оконные функции.

## Задача 3. Python
### Цель проекта:  
- написать функцию для обновления данных и пересчёта метрик;
- написать функцию для визуализации пересчитываемых метрик.

### В мои задачи входило: 
- разработка логики работы функций;
- написание целевых и вспомогательных функций на Python.

### Результат:  
- функция обновления данных дополняет данные, выдаёт датафрэйм с метриками, рассчитанными на каждом этапе обновления;
- функция визуализации метрик берёт на вход датафрэйм, полученный функцией обновления и строит 6 графиков: 4 метрики и 2 графика распределения данных.

### В работе использовались:
- библиотеки pandas, seaborn, matplotlib.pyplot для обработки и визуализации данных.

---

## [E-commerce проект, анализ покупок](https://github.com/RomanFeofanov/my_projects/blob/main/Project_1.ipynb/"Ссылка на проект")
### Цель проекта:  
- выбрать критерии, определяющие что считать покупкой и какой товар считать недоставленным;  
- определить количество пользователей, сделавших только одну покупку;
- определить, сколько заказов в месяц в среднем не доставляется по разным причинам;  
- определить в какой день недели чаще всего покупаюется каждый из товаров;  
- сколько у каждого пользователя в среднем покупок в неделю (по месяцам);  
- провести когортный анализ и выявить когорту с самым высоким retention на 3-й месяц;   
- построить RFM-кластеры для пользователей и вывести для каждого кластера средние значения метрик R, F, M  

### В мои задачи входило:   
- объединение 3-х датасетов;   
- анализ данных для определения критериев;  
- расчёт необходимых показателей;  
- написание функций на Python;     
- проведение RFM-анализа.  

### Результат:  
- за совершенную покупку принял факт наличия подтверждения заказа;  
- всё, что имеет статус отличный от `delivered` решено считать недоставленным;  
- найдено количество не доставленных заказов ко каждому статусу;  
- найден датасет с уникальными пользователями и днями недели, в которые покупки совершаются чаще всего;
- проведен когортный анализ пользователей;  
- выявлена когорта с самым высоким retention на 3-й месяц;  
- выполнен RFM-анализ, созданы функции для подсчета r,f,m метрик. Подсчитаны rfm метрики, и на их основе сформированы 9 сегментов, а также написана функция для присвоения новых сегментов. Данные были визуализированы для анализа.

### В работе использовались:   
- визуально-аналитический метод сегментации по графикам;  
- основные библиотеки: pandas, numpy, seaborn, matplotlib.pyplot, requests, urllib.   

---

## SQL  
### Цель проекта:   
- Выгрузить нужные данные из Postgresql и проанализировать их.  

### В мои задачи входило:   
- .  

### Результат:  
- .  

### В работе использовались:   
- СУБД Postgresql, Redash.   

---

## Мини проекты по статистике

## AA-test.ipynb  
Цель проекта:  
- Проверить утверждение о поломке сплит-системы с помощью A/A-теста мобильного приложения и найти ее причины.  

### Результат:  
- проведён А/А-тест;  
- найдена причина неправильной работы сплит системы: неверное деление на группы пользователей приложения версии v2.8.0.  

### В работе использовалась:   
- метрика качества FPR  

## AB-test_churn.ipynb  
### Цель проекта:  
- изучить отток водителей и посмотреть, какие есть различия между водителями, которые покидают сервис, и которые остаются.   

### Результат:  
- проведён А/B-тест;  
- выделины группы водителей, которые наиболее подвержены "оттоку": ушедшие пользователи были менее активны.

### В работе использовалась:  
- критерий хи-квадрат;  
- Шапиро-тест на нормальность распределения;
- критерий Краскела-Уоллиса.  

## AB_test.ipynb  
### Цель проекта:  
- проверить эффективрость нового алгоритма работы приложения для курьеров.  
### Результат:  
- определено, что среднее время доставки в тесте меньше, чем в контроле, принято решение использовать новый алгоритм на всех пользователей.  
### В работе использовалась:  
- тест проверки на нормальность распределения Шапиро-Уилка;  
- тест Стьюдента.    


## anova.ipynb  
### Цель проекта:  
- оценить результаты теста разрешений фотографий блюд в приложении;  
- оценить результаты теста изменения дизайна кнопки заказа в приложении.
### Результат:  
- выбран квадратный формат картинок, как наилучший;  
- выбран новый дизайн кнопки заказа приложений.  
### В работе использовалась:  
- статистический тест ANOVA;  
- тест гомогенности Левена;  
- тест Шапиро-Уилка, normaltest, и qq-графики для оценки нормальности рпспределений;  
- критерий Тьюки для выявления статистически значимых различий.  

## bootstrap_u-test.ipynb  
### Цель проекта:  
- сравните результат между тестом и контролем по двум кейсам: бутстрапом и u-тестом.  
### Результат:  
- сделаны выводы:
    - бутстрап с функцией np.mean чувствителен к выбросам в данных;  
    - бутстрап с функцией np.median и критерий Манна-Уитни не чувствительны к выбросам в данных;   
    - татистически значимых различий между тестовой и контрольной групп нет.  
### В работе использовалась:  
- бутстрап (с np.mean);  
- бутстрап (с np.median);  
- критерий mann-whitney.   


## conversion.ipynb  
### Цель проекта: 
- проанализировать CTR с разбивкой по рекламной кампании;  
- посчитайть стоимость за клик пользователя по объявлению (CPC);  
- визуализировать CPC с разбивкой по полу пользователей;  
- посчитать конверсию из клика в покупку.  
### Результат:  
- визуализирован CTR с разбивкой по номеру рекламной кампании;
- в исходный датафрейм добавлена колонка с CPC;  
- визуализирована CPC с разбивкой по полу пользователей;
- в исходный датафрейм добавлена колонка с CR в покупку.
### В работе использовалась:  
- модули Python: pandas, numpy, seaborn, scipy.stats, requests, urlencode.

## games.ipynb  
### Цель проекта:  
- выяснить на каких платформах произошло больше всего релизов;  
- выяснить игры каких издателей встречаются в датасете чаще всего;  
- найти регион с наибольшим медианным значением объема продаж игр Nintendo;  
- визуализировать динамику изменения объема мировых продаж по годам для игр Nintendo следующих жанров: Fighting, Simulation, Platform, Racing, Sports.
### Результат:  
- найдены наиболее популярные платформы: 'DS', 'PS2', 'PS3', 'Wii', 'X360', 'PSP', 'PS';  
- найдены наиболее популярные издатели: 'Electronic Arts', 'Activision', 'Namco Bandai Games', 'Ubisoft', 'Konami Digital Entertainment';  
- рассчитаны меры центральной тенденции объёма продаж игр Nintendo для каждого региона;  
- выявлено, что по наибольшим средним и медианным значением объема продаж игр Nintendo лидирует North America;  
- установлено, что медианное значение продаж игр жанра Fighting выше, чем у игр Simulation;  

### В работе использовались:  
- pandas;  
- numpy;   
- seaborn; 
- requests;  
- urlencode.  

## linear_regression.ipynb  
### Цель проекта:  
- предсказать стоимость автомобилей;  
- понять, от каких факторов зависит ценообразование на автомобили.
### Результат:  
- построена модель линейной регрессии для предсказания стоимости автомобилей; 
- выявлено, что среди предикторов 10 из 27 оказались не значимыми;  
### В работе использовалась:  
- pandas;  
- statsmodels.formula.api;  
- statsmodels.api.


## london_bicycle_rental.ipynb  
### Цель проекта:  
- объяснить аномалии на графике динамики числа аренд велосипедов.  
### Результат:  
- выявлено, что причина аномалий - ошибка в данных.
### В работе использовалась:  
- скользящее среднее;  
- seaborn;  
- pandas;  
- numpy;  
- requests;  
- urlencode.  

